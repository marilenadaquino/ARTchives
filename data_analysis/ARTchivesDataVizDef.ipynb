{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARTchives: a data driven historiography of art history - Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook is integral part of the research carried out by Lucia Giagnolini for her master's thesis in Knowledge organization and Cultural Heritage, Digital Humanities and Digital Knowledge international degree a. y. 2020/2021."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The focus of the thesis is the recently published ARTchives project, which can be accessed at: http://artchives.fondazionezeri.unibo.it. ARTchives is the first international web-based platform for a census of art historians' archives. It is an integrated system that collects archival descriptions of notable art historians' collections and opens up unexplored research paths through the implementation of semantic web technologies. Being a nascent project, there is considerable margin for improvement in several aspects. At the moment, one of the most compelling needs is to better exploit the potential of ARTchives and, in particular, of Semantic Web technologies underlying the system. A way to achieve this goal is to enhance communication and visual aspects by introducing new data visualizations to the ones aready published in the dedicated section.\n",
    "The work presented in this Notebook aims at providing further data visualization proposals, not yet published in the application but in the view of an actual implementation in the next releases of ARTchives. The starting point for the development of these visualizations were four fundamental research questions:\n",
    "1. RQ1. What have been the places of education and activity of all the art historians recorded in ARTchives?\n",
    "2. RQ2. What have been the places of education and activity of a particular art historian recorded in ARTchives?\n",
    "3. RQ3. What were the relations of art historians with other experts of their times (other scholars, art collectors, connoisseurs etc.)?\n",
    "4. RQ4. Which artists and personalities have been studied by art historians recorded in ARTchives?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The distribution of art historiansâ€™ places of education and activity: visualizing RQ1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#! pip install rdflib\n",
    "import rdflib\n",
    "from rdflib import Namespace , Literal , URIRef\n",
    "from rdflib.namespace import RDF , RDFS\n",
    "\n",
    "# create an empty Graph\n",
    "g = rdflib.ConjunctiveGraph()\n",
    "\n",
    "# parse a local RDF file by specifying the format\n",
    "result = g.parse(\"artchives.nq\", format='nquads') #Desktop/dhdk_epds/resources/\n",
    "\n",
    "# bind the uncommon namespaces\n",
    "wd = Namespace(\"http://www.wikidata.org/entity/\") # remember that a prefix matches a URI until the last slash (or hashtag #)\n",
    "wdt = Namespace(\"http://www.wikidata.org/prop/direct/\")\n",
    "art = Namespace(\"https://w3id.org/artchives/\")\n",
    "rdfs = Namespace (\"http://www.w3.org/2000/01/\")\n",
    "\n",
    "# Get the list of art historians in our graph \"g\"\n",
    "arthistorians_list = set()\n",
    "arthistorians_names = list()\n",
    "\n",
    "# iterate over the triples in the graph\n",
    "for s,p,o in g.triples(( None, wdt.P170, None)):\n",
    "    for subj, prop, obj in g.triples((o, RDFS.label, None )):# people \"o\" are the creator \"wdt.P170\" of a collection \"s\"\n",
    "        if \"wikidata.org/entity/\" in str(o):           # look for the substring to filter wikidata entities only\n",
    "            arthistorians_list.add('<' + str(o) + '>')\n",
    "            if obj.strip() not in arthistorians_names:\n",
    "                arthistorians_names.append(obj.strip())\n",
    "                arthistorians_names.append('<' + str(o) + '>')  # remember to transform them in strings! \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install SPARQLWrapper\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import ssl\n",
    "import os.path\n",
    "import json\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# get the endpoint API\n",
    "wikidata_endpoint = \"https://query.wikidata.org/bigdata/namespace/wdq/sparql\"\n",
    "\n",
    "if os.path.isfile(\"query1.json\"):\n",
    "    f = open('query1.json')\n",
    "    results = json.load(f)\n",
    "\n",
    "    # prepare the values to be queried\n",
    "else:\n",
    "    historians = ' '.join(arthistorians_list) # <uri1> <uri2> <uri3> ... <uriN>\n",
    "    # prepare the query: for each historian in ARTchives check in wikidata if there are work or education places.\n",
    "    formationplace_query = \"\"\" \n",
    "    PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "    SELECT DISTINCT ?historian ?workplace ?workplace_label ?coordinates1 ?eduplace ?eduplace_label ?coordinates2\n",
    "    WHERE {\n",
    "            VALUES ?historian {\"\"\"+historians+\"\"\"} . \n",
    "            optional {?historian wdt:P108 ?workplace . \n",
    "            ?workplace rdfs:label ?workplace_label .\n",
    "            FILTER (langMatches(lang(?workplace_label), \"EN\")) \n",
    "            ?workplace wdt:P625 ?coordinates1; wdt:P31 ?type . \n",
    "            ?type rdfs:label ?type_label . \n",
    "            FILTER (langMatches(lang(?type_label), \"EN\"))}\n",
    "            optional {?historian wdt:P69 ?eduplace . \n",
    "            ?eduplace rdfs:label ?eduplace_label .\n",
    "            FILTER (langMatches(lang(?eduplace_label), \"EN\")) \n",
    "            ?eduplace wdt:P625 ?coordinates2; wdt:P31 ?type . \n",
    "            ?type rdfs:label ?type_label . \n",
    "            FILTER (langMatches(lang(?type_label), \"EN\")) }\n",
    "            } \n",
    "    GROUP BY ?historian ?workplace ?workplace_label ?coordinates1 ?eduplace ?eduplace_label ?coordinates2 \n",
    "    \"\"\"\n",
    "     \n",
    "    user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.2 Safari/605.1.15'\n",
    "        # set the endpoint \n",
    "    sparql_wd = SPARQLWrapper(wikidata_endpoint, agent=user_agent)\n",
    "            # set the query\n",
    "    sparql_wd.setQuery(formationplace_query)\n",
    "            # set the returned format\n",
    "    sparql_wd.setReturnFormat(JSON)\n",
    "            # get the results\n",
    "    results = sparql_wd.query().convert()\n",
    "\n",
    "    with open('query1.json', 'w') as f:\n",
    "        json.dump(results, f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # manipulate the result\n",
    "for result in results[\"results\"][\"bindings\"]:\n",
    "    #print(result)\n",
    "    historian_uri = result[\"historian\"][\"value\"]\n",
    "    #print(\"historian:\", historian_uri)\n",
    "    if \"workplace\" in result: \n",
    "        workplace = result[\"workplace\"][\"value\"]\n",
    "        if \"workplace_label\" in result and \"coordinates1\" in result: \n",
    "            workplace_label = result[\"workplace_label\"][\"value\"]\n",
    "            work_coord = result[\"coordinates1\"][\"value\"][6:-1].split(\" \")\n",
    "            #print(work_coord)\n",
    "            #print(\"work:\", workplace, workplace_label)\n",
    "\n",
    "                    # only if uri, label and coords are found we add them to the graph\n",
    "            g.add(( URIRef(historian_uri) , URIRef(wdt.P108) , URIRef(workplace) ))\n",
    "            g.add(( URIRef(workplace) , RDFS.label , Literal(workplace_label) ))\n",
    "            g.add(( URIRef(workplace) , URIRef(wdt.P625) , Literal(work_coord) ))\n",
    "            \n",
    "                    \n",
    "            \n",
    "    if \"eduplace\" in result: \n",
    "        eduplace = result[\"eduplace\"][\"value\"]\n",
    "        #print(eduplace)\n",
    "        if \"eduplace_label\" in result and \"coordinates2\" in result: \n",
    "            eduplace_label = result[\"eduplace_label\"][\"value\"]\n",
    "            eduplace_coord = result[\"coordinates2\"][\"value\"][6:-1].split(\" \")\n",
    "            #print(\"education:\", eduplace, eduplace_label)\n",
    "                    # only if both uri and label are found we add them to the graph\n",
    "            g.add(( URIRef(historian_uri) , URIRef(wdt.P69) , URIRef(eduplace) ))\n",
    "            g.add(( URIRef(eduplace) , RDFS.label , Literal(eduplace_label) ))\n",
    "            g.add(( URIRef(eduplace) , URIRef(wdt.P625) , Literal(eduplace_coord) ))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.serialize(destination='artchives2.nq', format='nquads') #Desktop/dhdk_epds/resources/\n",
    "result = g.parse(\"artchives2.nq\", format='nquads')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loc_list = ['country', 'city', 'village', 'capital', 'state', 'region', 'municipality', 'county', 'frazione', 'comune', 'city-state', 'enclave']\n",
    "firstdict = {}\n",
    "final = {}\n",
    "for hist, prop, place in g.triples((None, wdt.P69, None)):\n",
    "    for eduplace, hasname, eduplacename in g.triples((place, RDFS.label, None)):\n",
    "        for edup, hascoordinates, coord in g.triples((eduplace, wdt.P625, None)):\n",
    "            for historian, p, name in g.triples(( hist, RDFS.label, None)):\n",
    "                if \"wikidata.org/entity/\" in str(historian):\n",
    "                    loc = 'institution'\n",
    "                    key = (eduplacename.strip(), \"<\" + place.strip() +\">\", float(coord.split(\" \")[1][1:-2][0:6]), float(coord.split(\" \")[0][2:-2][0:6]), loc)\n",
    "                    value = tuple([\"<\" + hist.strip() +\">\", name.strip()])\n",
    "                    if key not in firstdict.keys():\n",
    "                        firstdict[key] = set([value])\n",
    "                    else:\n",
    "                        firstdict[key].update([value])\n",
    "\n",
    "\n",
    "                    \n",
    "for hist, prop, place in g.triples((None, wdt.P108, None)):\n",
    "    for place, hasname, workplacename in g.triples((place, RDFS.label, None)):\n",
    "        for place, hasCoordinates, coord in g.triples((place, wdt.P625, None)):\n",
    "            for historian, p, name in g.triples(( hist, RDFS.label, None)):   \n",
    "                if \"wikidata.org/entity/\" in str(historian):\n",
    "                    loc = 'institution'\n",
    "                    key = (workplacename.strip(), \"<\" + place.strip() +\">\", float(coord.split(\" \")[1][1:-2][0:6]), float(coord.split(\" \")[0][2:-2][0:6]), loc)\n",
    "                    value = tuple([\"<\" + hist.strip() +\">\", name.strip()])\n",
    "                    if key not in firstdict.keys():\n",
    "                        firstdict[key] = set([value])\n",
    "                    else:\n",
    "                        firstdict[key].update([value])\n",
    "\n",
    "\n",
    "for k, v in firstdict.items(): #creation of a dictionary that has as key a tuple with the info for a place and as values a list of tuples of art historians connected to that place.\n",
    "    for el in v:\n",
    "        if k not in final.keys():\n",
    "            final[k] = [el]\n",
    "        else:\n",
    "            final[k].append(el)\n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "related = {} #dictionary to collect the main subjects of an art historian -p921- present in ARTchives data \n",
    "for s,p,o in g.triples(( None, wdt.P170, None)):   \n",
    "    if \"wikidata.org/entity/\" in str(o):           \n",
    "        for hist, prop, obj in g.triples((o, wdt.P921, None)):     \n",
    "            for subj, pr, name in g.triples(( hist, RDFS.label, None)):   \n",
    "                key = tuple(['<' + str(hist) + '>', name.strip()])\n",
    "                value = '<' + str(obj) + '>'\n",
    "                if key not in related.keys(): #the dict has as keys the historians and as values the relative list of main subjects.\n",
    "                    related[key] = [value]\n",
    "                else:\n",
    "                    related[key].append(value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import json\n",
    "\n",
    "related_dict= {}\n",
    "\n",
    "\n",
    "for k, v in related.items():  #for each art historian I extract those main subjects which are defined as places in wikidatata \n",
    "    relatedlist = ' '.join(v)\n",
    "    query_results = \"\"\"\n",
    "        PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "        SELECT DISTINCT ?place ?place_label ?coord (group_concat(?type_label ; separator=\"; \") as ?label) \n",
    "        WHERE {\n",
    "            VALUES ?place {\"\"\"+relatedlist+\"\"\"} . \n",
    "            ?place rdfs:label ?place_label . \n",
    "            FILTER (langMatches(lang(?place_label), \"EN\")) . \n",
    "            ?place wdt:P625 ?coord; wdt:P31 ?type . \n",
    "            ?type rdfs:label ?type_label . \n",
    "            FILTER (langMatches(lang(?type_label), \"EN\"))\n",
    "            } \n",
    "            group by ?place ?place_label ?coord ?label\n",
    "        \"\"\"\n",
    "\n",
    "    user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.2 Safari/605.1.15'\n",
    "    sparql_wd = SPARQLWrapper(wikidata_endpoint, agent=user_agent)\n",
    "    sparql_wd.setQuery(query_results)\n",
    "        # set the endpoint \n",
    "        #sparql_wd = SPARQLWrapper(wikidata_endpoint)\n",
    "        # set the query\n",
    "        #sparql_wd.setQuery(\n",
    "        # set the returned format\n",
    "    sparql_wd.setReturnFormat(JSON)\n",
    "        # get the results\n",
    "    results = sparql_wd.query().convert()\n",
    "    \n",
    "\n",
    "\n",
    "    for result in results[\"results\"][\"bindings\"]:\n",
    "            #print(v, result)\n",
    "        place = '<' + str(result[\"place\"][\"value\"]) + '>'\n",
    "        place_name = result[\"place_label\"][\"value\"]\n",
    "        coord = result[\"coord\"][\"value\"][6:-1].split(\" \")\n",
    "        type_label = result[\"label\"][\"value\"].split(\"; \")[0]\n",
    "        type_label_list = type_label.split(\" \")\n",
    "        check =  any(item in loc_list for item in type_label_list)\n",
    "        if check:\n",
    "            loc = \"geoloc\"\n",
    "        else:\n",
    "            loc = 'institution'\n",
    "        key = tuple([place_name, place, float(coord[1][0:6]), float(coord[0][0:6]), loc])\n",
    "        for value in v:\n",
    "            if value == str(key[1]):\n",
    "                if key not in related_dict.keys():\n",
    "                    related_dict[key] = set([k])\n",
    "                else: \n",
    "                    related_dict[key].update([k])\n",
    "                             \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "for k, v in final.items():\n",
    "    for el in v:\n",
    "        if k not in related_dict.keys():\n",
    "            related_dict[k] = set([el])\n",
    "        else:\n",
    "            related_dict[k].update([el])\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#If runned in Binder, click on File > Trust Notebook to properly visualize maps\n",
    "#!pip install ipywidgets\n",
    "#!pip install ipyleaflet\n",
    "from ipywidgets import HTML\n",
    "\n",
    "from ipyleaflet import Map, Marker, Popup, LayersControl, AwesomeIcon\n",
    "\n",
    "center = (41.080684, -30.683374)\n",
    "\n",
    "\n",
    "m = Map(center=center, zoom=3, close_popup_on_click=False)\n",
    "\n",
    "\n",
    "\n",
    "for k,v in related_dict.items():\n",
    "    names = []\n",
    "    for value in v:\n",
    "        if value[0] not in names:\n",
    "            names.append(\"<a href='http://artchives.fondazionezeri.unibo.it/historian-\" + value[0][32:-1] + \"'>\" + value[1] + \"</a>\" + \". \")\n",
    "    namelist = \" \".join(names)\n",
    "    #print(namelist)\n",
    "    if 'geoloc' in k[4]:\n",
    "        icon2 = AwesomeIcon(\n",
    "        name = \"map-marker\",\n",
    "        marker_color='blue',\n",
    "        icon_color='white',\n",
    "        spin=False\n",
    "        )\n",
    "        marker = Marker(icon = icon2, location=(k[2], k[3]))\n",
    "        m.add_layer(marker)\n",
    "        #message = HTML()\n",
    "        #marker.popup = message\n",
    "        #message.description = \"\"\n",
    "    #message.value = \"<b>\" + k[0] + \"</b>\" + \"<br>\"  + namelist\n",
    "    else:\n",
    "        icon2 = AwesomeIcon(\n",
    "        name = \"bank\",\n",
    "        marker_color='green',\n",
    "        icon_color='white',\n",
    "        spin=False\n",
    "            )\n",
    "        marker = Marker(icon = icon2, location=(k[2], k[3]))\n",
    "        m.add_layer(marker)\n",
    "    message = HTML()\n",
    "    marker.popup = message\n",
    "    message.description = \"\"\n",
    "    message.value = \"<b>\" + k[0] + \"</b>\" + \"<br>\" + namelist\n",
    "    \n",
    "        \n",
    "\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The distribution of selected art historiansâ€™ places of education and activity: visualizing RQ2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_dict = {} #dict that has as keys art historians and as values the list of related places. \n",
    "hist_list = []\n",
    "for k, v in related_dict.items():\n",
    "    for value in v:\n",
    "        if value not in hist_list:\n",
    "            hist_list.append(value)\n",
    "    for el in hist_list:\n",
    "        if el in v:\n",
    "            if el not in hist_dict.keys():\n",
    "                hist_dict[el] = [k]\n",
    "            else:\n",
    "                hist_dict[el].append(k)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from ipyleaflet import LayerGroup\n",
    "import random \n",
    "center = (41.080684, -30.683374)\n",
    "\n",
    "colors = ['red', 'darkred', 'lightred', 'orange', 'beige', 'green', 'darkgreen', 'lightgreen', 'blue', 'darkblue', 'lightblue', 'purple', 'darkpurple', 'pink', 'cadetblue', 'gray', 'lightgray', 'black']\n",
    "\n",
    "\n",
    "m = Map(center=center, zoom=3, close_popup_on_click=False)\n",
    "control = LayersControl(position='topright')\n",
    "m.add_control(control)\n",
    "\n",
    "for k,v in hist_dict.items():\n",
    "    layer_group = LayerGroup(layers=(), name=k[1]) #creating different layers for different historians\n",
    "    m.add_layer(layer_group)\n",
    "    #print(k, v)\n",
    "    icon2 = AwesomeIcon(\n",
    "        name = \"map-marker\",\n",
    "        marker_color= random.choice(colors),\n",
    "        icon_color='white',\n",
    "        spin=False\n",
    "        )\n",
    "    for value in v:\n",
    "        marker = Marker(icon = icon2, location=(value[2], value[3]))\n",
    "        message = HTML()\n",
    "        marker.popup = message\n",
    "        message.description = \"\"\n",
    "        message.value =\"<b>\" + \"<a href='http://artchives.fondazionezeri.unibo.it/historian-\" + k[0][32:-1] +\"'>\" + k[1] + \"</a>\" + \"</b>\" + \"<br>\"  + value[0]\n",
    "        layer_group.add_layer(marker)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The distribution of art historiansâ€™ relations with experts of their times: visualizing RQ3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "people = []\n",
    "for k, v in related.items():   \n",
    "    relatedlist = ' '.join(v)\n",
    "    #print(relatedlist)\n",
    "    query_res = \"\"\"\n",
    "        PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "        PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "        SELECT DISTINCT ?person ?person_label ?occupation ?deathdate\n",
    "        WHERE {\n",
    "            VALUES ?person {\"\"\"+relatedlist+\"\"\"} . \n",
    "            ?person wdt:P31 wd:Q5; rdfs:label ?person_label . \n",
    "            VALUES ?occupation {wd:Q1792450 wd:Q201788 wd:Q36180 wd:Q4164507 wd:Q1126160 wd:Q10732476 wd:Q1622272 wd:Q22132694} .  \n",
    "            ?person wdt:P106 ?occupation ; wdt:P570 ?deathdate.\n",
    "            FILTER (langMatches(lang(?person_label), \"EN\") ) \n",
    "            } \n",
    "\n",
    "        \"\"\"\n",
    "    user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.2 Safari/605.1.15'\n",
    "    # set the endpoint \n",
    "    sparql_wd = SPARQLWrapper(wikidata_endpoint, agent=user_agent)\n",
    "    # set the query\n",
    "    sparql_wd.setQuery(query_res)\n",
    "    # set the returned format\n",
    "    sparql_wd.setReturnFormat(JSON)\n",
    "    # get the results\n",
    "    results = sparql_wd.query().convert()\n",
    "\n",
    "    for result in results[\"results\"][\"bindings\"]:\n",
    "        #print(result)\n",
    "        person = '<' + str(result[\"person\"][\"value\"]) + '>'\n",
    "        person_name = str(result[\"person_label\"][\"value\"])\n",
    "        death_date = int(result[\"deathdate\"][\"value\"][0:4])\n",
    "        key = tuple([person_name, person])\n",
    "        if death_date > 1850:\n",
    "            for value in v:\n",
    "                if value == str(key[1]):\n",
    "                    tupla = tuple([k[1], k[0], person_name, person, 2])\n",
    "                    if tupla not in people:\n",
    "                        people.append(tupla)\n",
    "\n",
    "            \n",
    "#print(people)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coll_related = {}\n",
    "for coll,p,hist in g.triples(( None, wdt.P170, None)):\n",
    "    for historian, proper, hist_name in g.triples((hist, RDFS.label, None)):     # people \"o\" are the creator \"wdt.P170\" of a collection \"s\"\n",
    "        for collection, pr, coll_name in g.triples(( coll, RDFS.label, None)):   \n",
    "            for col, prop, content in g.triples((coll, wdt.P921, None)):     \n",
    "                for cont, pro, content_label in g.triples(( content, RDFS.label, None)): \n",
    "                    if \"wikidata.org/entity/\" in str(content):    \n",
    "                        key = tuple([hist_name.strip(), '<' + str(hist) + '>'])\n",
    "                        value = '<' + str(content) + '>'\n",
    "                        if key not in coll_related.keys():\n",
    "                            coll_related[key] = set([value])\n",
    "                        else:\n",
    "                            coll_related[key].add(value)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "collection_related = {}\n",
    "for coll,p,hist in g.triples(( None, wdt.P170, None)):\n",
    "    for historian, proper, hist_name in g.triples((hist, RDFS.label, None)):     \n",
    "        for collection, pr, coll_name in g.triples(( coll, RDFS.label, None)):   \n",
    "            for col, prop, content in g.triples((coll, art.hasSubjectPeople, None)):     \n",
    "                for cont, pro, content_label in g.triples(( content, RDFS.label, None)): \n",
    "                    if \"wikidata.org/entity/\" in str(content):    \n",
    "                        key = tuple([hist_name.strip(), '<' + str(hist) + '>'])\n",
    "                        value = '<' + str(content) + '>'\n",
    "                        if key not in collection_related.keys():\n",
    "                            collection_related[key] = set([value])\n",
    "                        else:\n",
    "                            collection_related[key].add(value)\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in collection_related.items(): \n",
    "    collection_list = ' '.join(v)\n",
    "    query_res = \"\"\"\n",
    "        PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "        PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "        PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "        SELECT DISTINCT ?person ?person_label \n",
    "        WHERE {\n",
    "            VALUES ?person {\"\"\"+collection_list+\"\"\"} . \n",
    "            ?person wdt:P31 wd:Q5; rdfs:label ?person_label \n",
    "            FILTER (langMatches(lang(?person_label), \"EN\")) . \n",
    "            }  \n",
    "\n",
    "        \"\"\"\n",
    "    user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.2 Safari/605.1.15'\n",
    "    # set the endpoint \n",
    "    sparql_wd = SPARQLWrapper(wikidata_endpoint, agent=user_agent)\n",
    "    # set the query\n",
    "    sparql_wd.setQuery(query_res)\n",
    "    # set the returned format\n",
    "    sparql_wd.setReturnFormat(JSON)\n",
    "    # get the results\n",
    "    results = sparql_wd.query().convert()\n",
    "\n",
    "    for result in results[\"results\"][\"bindings\"]:\n",
    "        #print(result)\n",
    "        person = '<' + str(result[\"person\"][\"value\"]) + '>'\n",
    "        person_name = str(result[\"person_label\"][\"value\"])\n",
    "        key = tuple([person_name, person])\n",
    "        for value in v:\n",
    "            if value == str(key[1]):\n",
    "                tupla = tuple([k[0], k[1], person_name, person, 3])\n",
    "                if tupla not in people:\n",
    "                    #print(tupla)\n",
    "                    people.append(tupla)\n",
    "                    \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in coll_related.items(): \n",
    "    coll_list = ' '.join(v)\n",
    "    query_res = \"\"\"\n",
    "        PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "        PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "        PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "        SELECT DISTINCT ?person ?person_label ?occupation ?deathdate\n",
    "        WHERE {\n",
    "            VALUES ?person {\"\"\"+coll_list+\"\"\"} . \n",
    "            ?person wdt:P31 wd:Q5; rdfs:label ?person_label \n",
    "            optional {?person wdt:P570 ?deathdate. FILTER (?deathdate > \"1850-01-01\"^^xsd:dateTime)} .\n",
    "            VALUES ?occupation {wd:Q1792450 wd:Q201788 wd:Q36180 wd:Q4164507 wd:Q1126160 wd:Q10732476 wd:Q1622272 wd:Q22132694}. \n",
    "            ?person wdt:P106 ?occupation .\n",
    "            FILTER (langMatches(lang(?person_label), \"EN\")) . \n",
    "            }  \n",
    "\n",
    "        \"\"\"\n",
    "    user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.2 Safari/605.1.15'\n",
    "    # set the endpoint \n",
    "    sparql_wd = SPARQLWrapper(wikidata_endpoint, agent=user_agent)\n",
    "    # set the query\n",
    "    sparql_wd.setQuery(query_res)\n",
    "    # set the returned format\n",
    "    sparql_wd.setReturnFormat(JSON)\n",
    "    # get the results\n",
    "    results = sparql_wd.query().convert()\n",
    "\n",
    "    for result in results[\"results\"][\"bindings\"]:\n",
    "        #print(result)\n",
    "        person = '<' + str(result[\"person\"][\"value\"]) + '>'\n",
    "        person_name = str(result[\"person_label\"][\"value\"])\n",
    "        key = tuple([person_name, person])\n",
    "        if \"deathdate\" in result: \n",
    "            death_date = int(result[\"deathdate\"][\"value\"][0:4])\n",
    "            if death_date > 1850 or \"deathdate\" not in result:\n",
    "                for value in v:\n",
    "                    if value == str(key[1]):\n",
    "                        tupla = tuple([k[0], k[1], person_name, person, 3])\n",
    "                        if tupla not in people and k[0] != person_name:\n",
    "                            people.append(tupla)\n",
    "\n",
    "#print(people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(\"query2.json\"):\n",
    "    f = open('query2.json')\n",
    "    results = json.load(f)\n",
    "else:\n",
    "    historians = ' '.join(arthistorians_list)\n",
    "    wdpeople_query = \"\"\" \n",
    "    PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "    PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "    SELECT DISTINCT ?historian ?student ?student_label ?master ?master_label ?influencer ?influencer_label ?signper ?signper_label ?birthdate ?deathdate \n",
    "    WHERE {\n",
    "            VALUES ?historian {\"\"\"+historians+\"\"\"} . \n",
    "            optional {?historian wdt:P802 ?student . \n",
    "            ?student rdfs:label ?student_label .\n",
    "            FILTER (langMatches(lang(?student_label), \"EN\")). \n",
    "            }\n",
    "            optional {?historian wdt:P1066 ?master . \n",
    "            ?master rdfs:label ?master_label .\n",
    "            FILTER (langMatches(lang(?master_label), \"EN\")). \n",
    "            }\n",
    "            optional {?historian wdt:P737 ?influencer . \n",
    "            ?influencer rdfs:label ?influencer_label .\n",
    "            FILTER (langMatches(lang(?influencer_label), \"EN\")).\n",
    "            } \n",
    "            optional {?historian wdt:P3342 ?signper . \n",
    "            ?signper rdfs:label ?signper_label .\n",
    "            FILTER (langMatches(lang(?signper_label), \"EN\")) . \n",
    "            }\n",
    "        } \n",
    "    \"\"\"\n",
    "    user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.2 Safari/605.1.15'\n",
    "    # set the endpoint \n",
    "    sparql_wd = SPARQLWrapper(wikidata_endpoint, agent=user_agent)\n",
    "        # set the query\n",
    "    sparql_wd.setQuery(wdpeople_query)\n",
    "        # set the returned format\n",
    "    sparql_wd.setReturnFormat(JSON)\n",
    "        # get the results\n",
    "    results = sparql_wd.query().convert()\n",
    "    \n",
    "    with open('query2.json', 'w') as f:\n",
    "        json.dump(results, f)\n",
    "\n",
    "\n",
    "\n",
    "for result in results[\"results\"][\"bindings\"]:\n",
    "    #print(result)\n",
    "    historian = result[\"historian\"][\"value\"]\n",
    "    if \"influencer\" in result: \n",
    "        influencer = result[\"influencer\"][\"value\"]\n",
    "        #print(influencer)\n",
    "        if \"influencer_label\" in result: \n",
    "            influencer_label = result[\"influencer_label\"][\"value\"]\n",
    "            #print(\"influencer:\", influencer, influencer_label)\n",
    "\n",
    "                    # only if both uri and label are found we add them to \n",
    "            g.add(( URIRef(historian) , URIRef(wdt.P737) , URIRef(influencer) ))\n",
    "            g.add(( URIRef(influencer) , RDFS.label , Literal(influencer_label) ))\n",
    "            \n",
    "           \n",
    "    if \"student\" in result: \n",
    "        student = result[\"student\"][\"value\"]\n",
    "        #print(historian)\n",
    "        if \"student_label\" in result: \n",
    "            student_label = result[\"student_label\"][\"value\"]\n",
    "            #print(\"historian:\", historian, \"student:\", student, student_label)\n",
    "\n",
    "                        # only if both uri and label are found we add them to \n",
    "            g.add(( URIRef(historian) , URIRef(wdt.P802) , URIRef(student) ))\n",
    "            g.add(( URIRef(student) , RDFS.label , Literal(student_label) )) \n",
    "           \n",
    "    \n",
    "    if \"master\" in result: \n",
    "        master = result[\"master\"][\"value\"]\n",
    "        if \"master_label\" in result: \n",
    "            master_label = result[\"master_label\"][\"value\"]\n",
    "            #print(\"historian:\", historian, \"master:\", master_label)\n",
    "\n",
    "                        # only if both uri and label are found we add them to \n",
    "            g.add(( URIRef(historian) , URIRef(wdt.P1066) , URIRef(master) ))\n",
    "            g.add(( URIRef(master) , RDFS.label , Literal(master_label) ))\n",
    "            \n",
    "                \n",
    "    \n",
    "    if \"signper\" in result: \n",
    "        signper = result[\"signper\"][\"value\"]\n",
    "        if \"signper_label\" in result: \n",
    "            signper_label = result[\"signper_label\"][\"value\"]\n",
    "            #print(\"signper:\", signper, signper_label)\n",
    "\n",
    "                        # only if both uri and label are found we add them to \n",
    "            g.add(( URIRef(historian) , URIRef(wdt.P3342) , URIRef(signper) ))\n",
    "            g.add(( URIRef(signper) , RDFS.label , Literal(signper_label) ))\n",
    "           \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.serialize(destination='artchives3.nq', format='nquads') #Desktop/dhdk_epds/resources/\n",
    "result = g.parse(\"artchives3.nq\", format='nquads')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hist, prop, influencer in g.triples((None, wdt.P737, None)):\n",
    "    #print(hist)\n",
    "    for influencer, hasname, influencername in g.triples((influencer, RDFS.label, None)):\n",
    "        for historian, p, name in g.triples(( hist, RDFS.label, None)):\n",
    "            if \"wikidata.org/entity/\" in str(hist):\n",
    "                tuplawd = tuple([name.strip(), \"<\" + hist.strip() +\">\", influencername.strip(), \"<\" + influencer.strip() +\">\", 1])\n",
    "                if tuplawd not in people:\n",
    "                    people.append(tuplawd)\n",
    "                \n",
    "for hist, prop, student in g.triples((None, wdt.P802, None)):\n",
    "    #print(hist)\n",
    "    for historian, p, name in g.triples(( hist, RDFS.label, None)):\n",
    "        for student, hasname, studentname in g.triples((student, RDFS.label, None)):\n",
    "            if \"wikidata.org/entity/\" in str(hist):  \n",
    "                tuplawd = tuple([name.strip(), \"<\" + hist.strip() +\">\", studentname.strip(), \"<\" + student.strip() +\">\", 1])\n",
    "                if tuplawd not in people:\n",
    "                    people.append(tuplawd)\n",
    "\n",
    "for hist, prop, master in g.triples((None, wdt.P1066, None)):\n",
    "    #print(hist)\n",
    "    for historian, p, name in g.triples(( hist, RDFS.label, None)):\n",
    "        for master, hasname, mastername in g.triples((master, RDFS.label, None)):\n",
    "            if \"wikidata.org/entity/\" in str(hist):  \n",
    "                tuplawd = tuple([name.strip(), \"<\" + hist.strip() +\">\", mastername.strip(), \"<\" + master.strip() +\">\", 1])\n",
    "                if tuplawd not in people:\n",
    "                    people.append(tuplawd)\n",
    "                \n",
    "                \n",
    "for hist, prop, signper in g.triples((None, wdt.P3342, None)):\n",
    "    #print(hist)\n",
    "    for historian, p, name in g.triples(( hist, RDFS.label, None)):\n",
    "        for signper, hasname, signpername in g.triples((signper, RDFS.label, None)):\n",
    "            if \"wikidata.org/entity/\" in str(hist):  \n",
    "                tuplawd = tuple([name.strip(), \"<\" + hist.strip() +\">\", signpername.strip(), \"<\" + signper.strip() +\">\", 1])\n",
    "                if tuplawd not in people:\n",
    "                    people.append(tuplawd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('people.csv', mode='w') as my_file:\n",
    "    my_writer = csv.writer(my_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_ALL)\n",
    "    # write the column names\n",
    "    my_writer.writerow(['art_hist', 'art_hist_uri','person', 'person_uri', 'weight'])\n",
    "    \n",
    "    # access the list of tuples of the query results\n",
    "    for res in people:\n",
    "        # write in the csv\n",
    "        my_writer.writerow([res[0], res[1], res[2], res[3], res[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install pandas\n",
    "import pandas as pd\n",
    "# parse the csv into a dataframe\n",
    "df = pd.read_csv(\"people.csv\")\n",
    "# print the first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install pyvis\n",
    "\n",
    "from pyvis import network as net\n",
    "\n",
    "\n",
    "\n",
    "people_net = net.Network(height=\"750px\", width=\"100%\", bgcolor=\"white\", font_color=\"#23f5ad\", notebook=\"True\", heading=\"The distribution of art historians' relations with experts of their times\")\n",
    "\n",
    "# set the physics layout of the network\n",
    "people_net.barnes_hut()\n",
    "people_data = pd.read_csv(\"people.csv\")\n",
    "\n",
    "sources = people_data['art_hist']\n",
    "targets = people_data['person']\n",
    "weights = people_data['weight']\n",
    "uri = people_data['art_hist_uri']\n",
    "\n",
    "edge_data = zip(sources, targets, weights)\n",
    "\n",
    "for e in edge_data:\n",
    "    #print(e)\n",
    "    src = e[0]\n",
    "    dst = e[1]\n",
    "    w = e[2]\n",
    "\n",
    "\n",
    "    people_net.add_node(src, src, title=src, color= \"#1cae81\", shape='dot')\n",
    "    people_net.add_node(dst, dst,  title=dst, color= \"#1cae81\", shape='dot')\n",
    "    if w == 1:\n",
    "        people_net.add_edge(src, dst, value=w, color=\"orange\")\n",
    "    elif w == 2:\n",
    "        people_net.add_edge(src, dst, value=w, color=\"grey\")\n",
    "    elif w == 3:\n",
    "        people_net.add_edge(src, dst, value=w, color=\"#1cae81\")\n",
    "\n",
    "neighbor_map = people_net.get_adj_list()\n",
    "\n",
    "# add neighbor data to node hover data\n",
    "for node in people_net.nodes:\n",
    "    #print(node)\n",
    "    node[\"title\"] = \"<b>\" + node[\"title\"] + \"</b>\"+ \" relations:<br>\" + \"<br>\".join(neighbor_map[node[\"id\"]])\n",
    "    node[\"size\"] = 70 + (len(neighbor_map[node[\"id\"]])*10)  #len(neighbor_map[node[\"id\"]]) #70 + (len(neighbor_map[node[\"id\"]])*10) \n",
    "    node[\"label\"] = node[\"id\"] \n",
    "    node[\"borderWidthSelected\"] = 5 \n",
    "    if node[\"label\"] in arthistorians_names:\n",
    "        node[\"color\"] = \"#23f5ad\"\n",
    "        uripos = arthistorians_names.index(node[\"label\"])+1\n",
    "        uri = arthistorians_names[uripos]\n",
    "        #print(node[\"label\"], uri)\n",
    "        #node[\"title\"] = \"<br>\" + \"<b>\" + \"<a href='http://artchives.fondazionezeri.unibo.it/historian-\" + uri[32:-1] + \"'>\" + node[\"label\"] + \"</a>\" +  \"</b>\" +  \"<i>\" + \"  relations:<br>\" + \"</i>\"+ \"<hr>\" + \"<br>\".join(neighbor_map[node[\"id\"]]) \n",
    "        node[\"title\"] = \"<br>\" + \"<b>\" + node[\"label\"] + \"</b>\" +  \"<i>\" + \"  relations:<br>\" + \"</i>\"+ \"<hr>\"+ \"<br>\".join(neighbor_map[node[\"id\"]]) + \"<br>\" \n",
    "    else: \n",
    "        node[\"title\"] = \"<br>\" + \"<b>\" + node[\"label\"] + \"</b>\" +  \"<i>\" + \"  relations:<br>\" + \"</i>\"+ \"<hr>\"+ \"<br>\".join(neighbor_map[node[\"id\"]]) + \"<br>\" \n",
    "        \n",
    "#print(len(people_net.edges))\n",
    "\n",
    "people_net.show(\"people.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. The distribution of art historiansâ€™ relations with their subjects of study: visualizing RQ4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_periods = g.query(\n",
    "        \"\"\"PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "        SELECT ?hist_label ?hist ?period (SAMPLE(?label) AS ?period_label) \n",
    "        WHERE {?coll <https://w3id.org/artchives/hasSubjectPeriod> ?period ; rdfs:label ?coll_label \n",
    "        . ?coll wdt:P170 ?hist . ?hist rdfs:label ?hist_label .\n",
    "        ?period rdfs:label ?label . \n",
    "        }\n",
    "        GROUP BY ?period ?label ?hist ?hist_label \n",
    "        ORDER BY ?period\"\"\")\n",
    "    \n",
    "\n",
    "\n",
    "periods = set()\n",
    "period_dict = {}\n",
    "period_dict_labels = {}\n",
    "for result in query_periods:\n",
    "    #print(result)\n",
    "    hist = tuple([result[0].strip(), '<' + str(result[1])+ '>'])\n",
    "    period = result[2].strip()\n",
    "    period_label = result[3].strip().lower()\n",
    "    #print(period)\n",
    "    if hist not in period_dict.keys():\n",
    "        period_dict[hist] = set([period])\n",
    "        period_dict_labels[hist] = set([period_label])\n",
    "    else:\n",
    "        period_dict[hist].add(period)\n",
    "        period_dict_labels[hist].add(period_label)\n",
    "    \n",
    "\n",
    "for k,v in period_dict.items():\n",
    "    #print(k, v)\n",
    "    for value in v:\n",
    "        periods.add('<' + str(value) + '>') \n",
    "\n",
    "periods_labels = set()\n",
    "for k,v in period_dict_labels.items():\n",
    "    for value in v:\n",
    "        periods_labels.add('<' + str(value) + '>') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "period_list = ' '.join(periods)\n",
    "period_res = \"\"\"\n",
    "            PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "            PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "            SELECT DISTINCT ?period ?period_label ?startdate ?enddate\n",
    "            WHERE {\n",
    "                VALUES ?period {\"\"\"+period_list+\"\"\"} . \n",
    "                ?period rdfs:label ?period_label; wdt:P580 ?startdate ; wdt:P582 ?enddate; \n",
    "                FILTER (langMatches(lang(?period_label), \"EN\"))\n",
    "\n",
    "                } \n",
    "            \"\"\"\n",
    "user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.2 Safari/605.1.15'\n",
    "    # set the endpoint \n",
    "sparql_wd = SPARQLWrapper(wikidata_endpoint, agent=user_agent)\n",
    "        # set the query\n",
    "sparql_wd.setQuery(period_res)\n",
    "        # set the returned format\n",
    "sparql_wd.setReturnFormat(JSON)\n",
    "        # get the results\n",
    "results = sparql_wd.query().convert()\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "dates_dict = {}\n",
    "for result in results[\"results\"][\"bindings\"]:\n",
    "    period = '<' + str(result[\"period\"][\"value\"]) + '>'\n",
    "    period_label = result[\"period_label\"][\"value\"]\n",
    "    start = int(result[\"startdate\"][\"value\"][0:4])\n",
    "    end = int(result[\"enddate\"][\"value\"][0:4])\n",
    "    key = tuple([period, period_label.lower()])\n",
    "    years = tuple([start, end])\n",
    "    if key not in dates_dict.keys():\n",
    "        dates_dict[key] = years\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_artists = {}\n",
    "related_artists_label = {}\n",
    "for coll,p,hist in g.triples(( None, wdt.P170, None)):\n",
    "    for historian, proper, hist_name in g.triples((hist, RDFS.label, None)):     \n",
    "        for collection, pr, coll_name in g.triples(( coll, RDFS.label, None)):   \n",
    "            for col, prop, content in g.triples((coll, art.hasSubjectArtist, None)):     \n",
    "                for cont, pro, content_label in g.triples(( content, RDFS.label, None)): \n",
    "                    if \"wikidata.org/entity/\" in str(content):    \n",
    "                        key = tuple([hist_name.strip(), '<' + str(hist) + '>'])\n",
    "                        value = '<' + str(content)+ '>'\n",
    "                        label = str(content_label.strip())                     \n",
    "                        if key not in related_artists.keys():\n",
    "                            related_artists[key] = set([value])\n",
    "                            related_artists_label[key] = set([label])\n",
    "                        else:\n",
    "                            related_artists[key].add(value)\n",
    "                            related_artists_label[key].add(label)\n",
    "\n",
    "\n",
    "#for k, v in related_artists_label.items():\n",
    "    #print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "artist_dict = {}\n",
    "for k, v in related_artists.items(): \n",
    "    art_list = ' '.join(v)\n",
    "    query_art = \"\"\"\n",
    "        PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "        PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "        SELECT DISTINCT ?person ?person_label ?birthdate ?deathdate\n",
    "        WHERE {\n",
    "            VALUES ?person {\"\"\"+art_list+\"\"\"} . \n",
    "            ?person wdt:P31 wd:Q5; rdfs:label ?person_label .\n",
    "            ?person wdt:P569 ?birthdate ; wdt:P570 ?deathdate.\n",
    "            FILTER (langMatches(lang(?person_label), \"EN\")) . \n",
    "            } \n",
    "\n",
    "        \"\"\"\n",
    "    user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.2 Safari/605.1.15'\n",
    "    # set the endpoint \n",
    "    sparql_wd = SPARQLWrapper(wikidata_endpoint, agent=user_agent)\n",
    "    # set the query\n",
    "    sparql_wd.setQuery(query_art)\n",
    "    # set the returned format\n",
    "    sparql_wd.setReturnFormat(JSON)\n",
    "    # get the results\n",
    "    results = sparql_wd.query().convert()\n",
    "\n",
    "    for result in results[\"results\"][\"bindings\"]:\n",
    "        artist = '<' + str(result[\"person\"][\"value\"]) + '>'\n",
    "        artist_name = str(result[\"person_label\"][\"value\"]) \n",
    "        death = str(result[\"deathdate\"][\"value\"]) \n",
    "        birth = str(result[\"birthdate\"][\"value\"])\n",
    "        key = tuple([artist, artist_name, int(birth[0:4]), int(death[0:4])])\n",
    "        for value in v:\n",
    "            if value == artist:\n",
    "                if key not in artist_dict.keys():      \n",
    "                    artist_dict[key] = set([k[0]])\n",
    "                else:\n",
    "                    artist_dict[key].add(k[0])\n",
    "\n",
    "#for k,v in artist_dict.items():\n",
    "    #print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "check_dict = {}\n",
    "for k, v in coll_related.items(): \n",
    "    coll_list = ' '.join(v)\n",
    "    query_res = \"\"\"\n",
    "        PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "        PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "        SELECT DISTINCT ?person ?person_label ?occupation ?birthdate ?deathdate\n",
    "        WHERE {\n",
    "            VALUES ?person {\"\"\"+coll_list+\"\"\"} . \n",
    "            ?person wdt:P31 wd:Q5; rdfs:label ?person_label .\n",
    "            VALUES ?occupation {wd:Q1281618 wd:Q42973 wd:Q483501 wd:Q1028181 wd:Q329439} . \n",
    "            ?person wdt:P106 ?occupation ; wdt:P569 ?birthdate ; wdt:P570 ?deathdate.\n",
    "            FILTER (langMatches(lang(?person_label), \"EN\")) . \n",
    "            } \n",
    "\n",
    "        \"\"\"\n",
    "    user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.2 Safari/605.1.15'\n",
    "    # set the endpoint  \n",
    "    sparql_wd = SPARQLWrapper(wikidata_endpoint, agent=user_agent)\n",
    "    # set the query\n",
    "    sparql_wd.setQuery(query_res)\n",
    "    # set the returned format\n",
    "    sparql_wd.setReturnFormat(JSON)\n",
    "    # get the results\n",
    "    results = sparql_wd.query().convert()\n",
    "\n",
    "    for result in results[\"results\"][\"bindings\"]:\n",
    "        #print(result)\n",
    "        artist = '<' + str(result[\"person\"][\"value\"]) + '>'\n",
    "        artist_name = str(result[\"person_label\"][\"value\"]) \n",
    "        death = str(result[\"deathdate\"][\"value\"]) \n",
    "        birth = str(result[\"birthdate\"][\"value\"])\n",
    "        key = tuple([artist, artist_name, int(birth[0:4]), int(death[0:4])])\n",
    "        \n",
    "        for value in v:\n",
    "            if value == artist:\n",
    "                if key not in check_dict.keys():      \n",
    "                    check_dict[key] = set([k[0]])\n",
    "                else:\n",
    "                    check_dict[key].add(k[0])\n",
    "               \n",
    "                \n",
    "#for k, v in check_dict.items():\n",
    "    #if k not in artist_dict.items():\n",
    "        #print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "artist_rel = list()\n",
    "for k, v in artist_dict.items():\n",
    "    for value in v:\n",
    "        tupla = tuple([k[1], value, 1])\n",
    "        if tupla not in artist_rel:\n",
    "            artist_rel.append(tupla)\n",
    "        for el in v:\n",
    "            if value != el:\n",
    "                tupla = tuple([el, value, 1])\n",
    "                tuplabis = tuple([value, el, 1])\n",
    "                if tuplabis not in artist_rel:\n",
    "                    artist_rel.append(tupla)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "count_dict = Counter(artist_rel)\n",
    "artist_rel_final = []\n",
    "\n",
    "for k, v in count_dict.items():\n",
    "    if v != 1:\n",
    "        x = list(k)\n",
    "        x[2] = v\n",
    "        k = tuple(x)\n",
    "    artist_rel_final.append(k)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k, v in coll_related.items():\n",
    "    #print(k, v)\n",
    "    for key, value in dates_dict.items():\n",
    "        #print(key, value)\n",
    "        for artist, hist in artist_dict.items():\n",
    "            #print(artist, hist)\n",
    "            if key[0] in v and artist[0] in v:\n",
    "                if (value[0] <= artist[2] and value[1] >= artist[3]) or (value[0] >= artist[2] and value[1] <= artist[3]) or (value[0] >= artist[2] and (value[1] + 15) >= artist[3] and artist[2] >= value[1]) or (value[0] <= artist[2] and (value[1] - 15) >= artist[2] and value[1] <= artist[3]):\n",
    "                    tupla = tuple([k[0], artist[1], 2])\n",
    "                    tupla_remove1 = tuple([k[0], artist[1], 1])\n",
    "                    tupla_remove2 = tuple([artist[1], k[0], 1])\n",
    "                    if tupla_remove1 in artist_rel_final: \n",
    "                        artist_rel_final.remove(tupla_remove1)\n",
    "                    elif tupla_remove2 in artist_rel_final: \n",
    "                        artist_rel_final.remove(tupla_remove2)\n",
    "                    artist_rel_final.append(tupla)\n",
    "                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('artists.csv', mode='w') as my_file:\n",
    "    my_writer = csv.writer(my_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_ALL)\n",
    "    # write the column names\n",
    "    my_writer.writerow(['subj1','subj2','weight'])\n",
    "    \n",
    "    # access the list of tuples of the query results\n",
    "    for res in artist_rel_final:\n",
    "        # write in the csv\n",
    "        my_writer.writerow([res[0], res[1], res[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the csv into a dataframe\n",
    "df = pd.read_csv(\"artists.csv\")\n",
    "# print the first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "people_net = net.Network(height=\"750px\", width=\"100%\", bgcolor=\"white\", font_color=\"#1cae81\", notebook=\"True\", heading=\"The distribution of art historians' relations with their subjects of study\")\n",
    "\n",
    "# set the physics layout of the network\n",
    "people_net.barnes_hut()\n",
    "people_data = pd.read_csv(\"artists.csv\")\n",
    "\n",
    "sources = people_data['subj1']\n",
    "targets = people_data['subj2']\n",
    "weights = people_data['weight']\n",
    "\n",
    "\n",
    "edge_data = zip(sources, targets, weights)\n",
    "\n",
    "for e in edge_data:\n",
    "    #print(e)\n",
    "    src = e[0]\n",
    "    dst = e[1]\n",
    "    w = e[2]\n",
    "\n",
    "\n",
    "    people_net.add_node(src, src, title=src, color= \"#1cae81\")\n",
    "    people_net.add_node(dst, dst, title=dst, color= \"#1cae81\")\n",
    "    if w == 1:\n",
    "        people_net.add_edge(src, dst, value=w, color=\"grey\")\n",
    "    elif w == 2:\n",
    "        people_net.add_edge(src, dst, value=w, color=\"#1cae81\")\n",
    "    elif w == 3:\n",
    "        people_net.add_edge(src, dst, value=w, color=\"black\")\n",
    "    \n",
    "        \n",
    "\n",
    "neighbor_map = people_net.get_adj_list()\n",
    "\n",
    "# add neighbor data to node hover data\n",
    "for node in people_net.nodes:\n",
    "    #print(node)\n",
    "    \n",
    "    node[\"size\"] = 80 + (len(neighbor_map[node[\"id\"]])*10)   \n",
    "    node[\"borderWidthSelected\"] = 5\n",
    "    node[\"label\"] = node[\"id\"] \n",
    "    historians = set()\n",
    "    artists = set()\n",
    "    for el in (neighbor_map[node[\"id\"]]):\n",
    "        if el in arthistorians_names:\n",
    "            historians.add(el)\n",
    "        else: \n",
    "            artists.add(el)\n",
    "    if node[\"label\"] in arthistorians_names:\n",
    "        node[\"color\"] = \"#23f5ad\"\n",
    "        uripos = arthistorians_names.index(node[\"label\"])+1\n",
    "        uri = arthistorians_names[uripos]\n",
    "        #print(node[\"label\"], uri)\n",
    "        if len(historians) > 0:\n",
    "            node[\"title\"] = \"<br>\" + \"<b>\" + node[\"label\"] +  \"</b>\" +  \"<i>\" + \"  relations:<br>\" + \"</i>\"+ \"<hr>\" + \"<b>\" + \"Subjects of study\" + \"</b>\" + \"<br>\" + \"<br>\".join(artists) + \"<br>\" + \"<hr>\"+ \"<b>\" + \"Art historians\" + \"</b>\" + \"<br>\" + \"<br>\".join(historians)  \n",
    "        else:\n",
    "            node[\"title\"] = \"<br>\" + \"<b>\" + node[\"label\"] +   \"</b>\" +  \"<i>\" + \"  relations:<br>\" + \"</i>\"+ \"<hr>\" + \"<b>\" + \"Subjects of study\" + \"</b>\" + \"<br>\" + \"<br>\".join(artists)\n",
    "    \n",
    "        #+ \"<a href='http://artchives.fondazionezeri.unibo.it/historian-\" + uri[32:-1] + \"'>\" + node[\"label\"] + \"</a>\" +\n",
    "    else: \n",
    "        node[\"title\"] = \"<br>\" + \"<b>\" + node[\"label\"] + \"</b>\" +  \"<i>\" + \"  relations:<br>\" + \"</i>\"+ \"<hr>\" + \"<b>\" + \"Art historians\" + \"</b>\" + \"<br>\" + \"<br>\".join(historians) + \"<br>\" \n",
    "   \n",
    "        #print(historians)\n",
    "        #print(artists)\n",
    "people_net.show(\"people.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for k, v in related_artists.items():\n",
    "    for key, value in period_dict.items():\n",
    "        if k in period_dict.keys() and k == key:\n",
    "            d[k] = related_artists[k].union(period_dict[key])\n",
    "        elif k not in period_dict.keys():\n",
    "            d[k] = related_artists[k]\n",
    "        elif key not in related_artists.keys():\n",
    "            d[key] = period_dict[key]\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_dict = {}\n",
    "for k, v in d.items():\n",
    "    for value in v:\n",
    "        if value not in mixed_dict:\n",
    "            mixed_dict[value] = [k[0]]\n",
    "        else:\n",
    "            mixed_dict[value].append(k[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodartist_tuples = []\n",
    "for k, v in mixed_dict.items():\n",
    "    for value in v:\n",
    "        for el in v:\n",
    "            if value != el:\n",
    "                tupla = tuple([el, value, 1])\n",
    "                tuplabis = tuple([value, el, 1])\n",
    "                if tuplabis not in periodartist_tuples:\n",
    "                    periodartist_tuples.append(tupla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_periodartist = []\n",
    "periodartist = Counter(periodartist_tuples)\n",
    "for k, v in periodartist.items():\n",
    "    tupla = (k[0], k[1], v)\n",
    "    final_periodartist.append(tupla)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('RQ4.json', 'w') as f:\n",
    "    json.dump(mixed_dict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
